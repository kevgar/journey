{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data into Hive using EMR cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (1) Create Your Own S3 Bucket"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "$ # Create s3 bucket\n",
    "$ aws s3api create-bucket --bucket kjgardner74-hive --region us-east-1\n",
    "$ # Create logs folder\n",
    "$ aws s3api put-object --bucket kjgardner74-hive --key logs/\n",
    "$ # Sync local folder to s3 bucket\n",
    "$ aws s3 sync ~/journey/hive-emr-setup s3://kjgardner74-hive/scripts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (2) Create an EMR Cluster"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "$ aws emr create-cluster --auto-scaling-role EMR_AutoScaling_DefaultRole --termination-protected --applications Name=Hadoop Naaws emr create-cluster --applications Name=Hadoop Name=Hive Name=Pig Name=Hue Name=Spark --ec2-attributes '{\"KeyName\":\"ec2-journey\",\"InstanceProfile\":\"EMR_EC2_DefaultRole\",\"SubnetId\":\"subnet-eaebacc7\",\"EmrManagedSlaveSecurityGroup\":\"sg-3e3cba41\",\"EmrManagedMasterSecurityGroup\":\"sg-eb3bbd94\"}' --service-role EMR_DefaultRole --enable-debugging --release-label emr-5.30.1 --log-uri 's3n://kjgardner74-hive/' --name 'emr-journey' --instance-groups '[{\"InstanceCount\":1,\"InstanceGroupType\":\"MASTER\",\"InstanceType\":\"m3.xlarge\",\"Name\":\"Master Instance Group\"}]' --configurations '[{\"Classification\":\"spark\",\"Properties\":{}}]' --scale-down-behavior TERMINATE_AT_TASK_COMPLETION --region us-east-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ssh into the cluster"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "$ aws emr ssh --cluster-id j-1CZ51HG5J04RV --key-pair-file ~/ec2-journey.pem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (3) Copy the zip file from S3 and unzip"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# copy data from s3 over to the master node\n",
    "$ aws s3 cp s3://kjgardner74-hive/journey/408408-782411-bundle-archive.zip 408408-782411-bundle-archive.zip\n",
    "\n",
    "# create a directory for the data\n",
    "$ mkdir -p journey\n",
    "\n",
    "# unzip the data\n",
    "$ unzip 408408-782411-bundle-archive.zip\n",
    "\n",
    "# rename the unzipped directory\n",
    "$ mv 408408-782411-bundle-archive journey\n",
    "\n",
    "# clean up the home directory\n",
    "$ rm -rf 408408-782411-bundle-archive.zip\n",
    "$ rm -rf __MACOSX/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy query scripts from S3"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "$ aws s3 cp s3://kgardn15-elasticmapreduce/scripts/create_hive_tables.hql create_hive_tables.hql\n",
    "$ aws s3 cp s3://kgardn15-elasticmapreduce/scripts/create_external_tables.hql create_external_tables.hql"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (4) Create a directory and copy data into hdfs"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "$ hdfs dfs -mkdir journey\n",
    "$ \n",
    "$ hdfs dfs -mkdir journey/transaction\n",
    "$ hdfs dfs -copyFromLocal journey/transaction_data.csv journey/transaction\n",
    "$ \n",
    "$ hdfs dfs -mkdir journey/product\n",
    "$ hdfs dfs -copyFromLocal journey/product.csv journey/product\n",
    "$ \n",
    "$ hdfs dfs -mkdir journey/hh_demographic\n",
    "$ hdfs dfs -copyFromLocal journey/hh_demographic.csv journey/hh_demographic\n",
    "$ \n",
    "$ hdfs dfs -mkdir journey/causal\n",
    "$ hdfs dfs -copyFromLocal journey/causal_data.csv journey/causal\n",
    "$ \n",
    "$ hdfs dfs -mkdir journey/coupon\n",
    "$ hdfs dfs -copyFromLocal journey/coupon.csv journey/coupon\n",
    "$ \n",
    "$ hdfs dfs -mkdir journey/coupon_redempt\n",
    "$ hdfs dfs -copyFromLocal journey/coupon_redempt.csv journey/coupon_redempt\n",
    "$ \n",
    "$ hdfs dfs -mkdir journey/campaign\n",
    "$ hdfs dfs -copyFromLocal journey/campaign_table.csv journey/campaign\n",
    "$ \n",
    "$ hdfs dfs -mkdir journey/campaign_desc\n",
    "$ hdfs dfs -copyFromLocal journey/campaign_desc.csv journey/campaign_desc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating tables in hive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a Demographic Table and Load Data into it. Then create a transaction table and load data."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "$ hive -hiveconf DATA_DIR=/home/journey/ -f create_hive_tables.hql"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "-- File: create_hive_tables.hql\n",
    "\n",
    "Create database journey;\n",
    "\n",
    "Use journey;\n",
    "\n",
    "/* --------------------\n",
    "load hh_demographic.csv\n",
    "-------------------- */\n",
    "\n",
    "CREATE TABLE hh_demographic\n",
    "(AGE_DESC VARCHAR(45),\n",
    "MARITAL_STATUS_CODE VARCHAR(10),\n",
    "INCOME_DESC VARCHAR(15),\n",
    "HOMEOWNER_DESC VARCHAR(45),\n",
    "HH_COMP_DESC VARCHAR(45),\n",
    "HOUSEHOLD_SIZE_DESC VARCHAR(20),\n",
    "KID_CATEGORY_DESC VARCHAR(5),\n",
    "HOUSEHOLD_KEY BIGINT)\n",
    "COMMENT 'Household Demographics in Journey'\n",
    "ROW FORMAT DELIMITED\n",
    "FIELDS TERMINATED BY ','\n",
    "LINES TERMINATED BY '\\n'\n",
    "tblproperties (\"skip.header.line.count\"=\"1\");\n",
    "\n",
    "LOAD DATA LOCAL INPATH 'journey/hh_demographic.csv' OVERWRITE INTO TABLE hh_demographic;\n",
    "\n",
    "/* --------------------\n",
    "load transaction_data.csv\n",
    "-------------------- */\n",
    "\n",
    "CREATE TABLE transaction\n",
    "(HOUSEHOLD_KEY INT,\n",
    "BASKET_ID BIGINT,\n",
    "DAY INT,\n",
    "PRODUCT_ID BIGINT,\n",
    "QUANTITY INT,\n",
    "SALES_VALUE DECIMAL(10,2),\n",
    "STORE_ID INT,\n",
    "RETAIL_DISC DECIMAL(5,2),\n",
    "TRANS_TIME INT,\n",
    "WEEK_NO INT,\n",
    "COUPON_DISC DECIMAL(6,2),\n",
    "COUPON_MATCH_DISC DECIMAL(6,2))\n",
    "COMMENT 'transactions in Journey'\n",
    "ROW FORMAT DELIMITED\n",
    "FIELDS TERMINATED BY ','\n",
    "LINES TERMINATED BY '\\n'\n",
    "tblproperties (\"skip.header.line.count\"=\"1\");\n",
    "\n",
    "LOAD DATA LOCAL INPATH 'journey/transaction_data.csv' OVERWRITE INTO TABLE transaction;\n",
    "\n",
    "/* --------------------\n",
    "load campaign_desc.csv\n",
    "-------------------- */\n",
    "\n",
    "CREATE TABLE campaign_desc\n",
    "(DESCRIPTION VARCHAR(15),\n",
    "CAMPAIGN INT,\n",
    "START_DAY INT,\n",
    "END_DAY INT)\n",
    "ROW FORMAT DELIMITED\n",
    "FIELDS TERMINATED BY ','\n",
    "LINES TERMINATED BY '\\n'\n",
    "tblproperties (\"skip.header.line.count\"=\"1\");\n",
    "\n",
    "LOAD DATA LOCAL INPATH 'journey/campaign_desc.csv' OVERWRITE INTO TABLE campaign_desc;\n",
    "\n",
    "/* --------------------\n",
    "load causal_data.csv\n",
    "-------------------- */\n",
    "\n",
    "CREATE TABLE causal\n",
    "(PRODUCT_ID BIGINT,\n",
    "STORE_ID INT,\n",
    "WEEK_NO INT,\n",
    "DISPLAY VARCHAR(5),\n",
    "MAILER VARCHAR(5))\n",
    "ROW FORMAT DELIMITED\n",
    "FIELDS TERMINATED BY ','\n",
    "LINES TERMINATED BY '\\n'\n",
    "tblproperties (\"skip.header.line.count\"=\"1\");\n",
    "\n",
    "LOAD DATA LOCAL INPATH 'journey/causal_data.csv' OVERWRITE INTO TABLE causal;\n",
    "\n",
    "/* --------------------\n",
    "load coupon_redempt.csv\n",
    "-------------------- */\n",
    "\n",
    "CREATE TABLE coupon_redempt\n",
    "(HOUSEHOLD_KEY BIGINT,\n",
    "DAY INT,\n",
    "COUPON_UPC BIGINT,\n",
    "CAMPAIGN INT)\n",
    "ROW FORMAT DELIMITED\n",
    "FIELDS TERMINATED BY ','\n",
    "LINES TERMINATED BY '\\n'\n",
    "tblproperties (\"skip.header.line.count\"=\"1\");\n",
    "\n",
    "LOAD DATA LOCAL INPATH 'journey/coupon_redempt.csv' OVERWRITE INTO TABLE coupon_redempt;\n",
    "\n",
    "/* --------------------\n",
    "load product.csv\n",
    "-------------------- */\n",
    "\n",
    "CREATE TABLE product\n",
    "(PRODUCT_ID INT,\n",
    "MANUFACTURER INT,\n",
    "DEPARTMENT STRING,\n",
    "BRAND STRING,\n",
    "COMMODITY_DESC STRING,\n",
    "SUB_COMMODITY_DESC STRING,\n",
    "CURR_SIZE_OF_PRODUCT STRING)\n",
    "COMMENT 'journey product list cleaned'\n",
    "ROW FORMAT DELIMITED\n",
    "FIELDS TERMINATED BY ','\n",
    "LINES TERMINATED BY '\\n'\n",
    "tblproperties (\"skip.header.line.count\"=\"1\");\n",
    "\n",
    "LOAD DATA LOCAL INPATH 'journey/product.csv' OVERWRITE INTO TABLE product;\n",
    "\n",
    "/* --------------------\n",
    "load campaign_table.csv\n",
    "-------------------- */\n",
    "\n",
    "CREATE TABLE campaign\n",
    "(DESCRIPTION VARCHAR(15),\n",
    "HOUSEHOLD_KEY BIGINT,\n",
    "CAMPAIGN INT)\n",
    "ROW FORMAT DELIMITED\n",
    "FIELDS TERMINATED BY ','\n",
    "LINES TERMINATED BY '\\n'\n",
    "tblproperties (\"skip.header.line.count\"=\"1\");\n",
    "\n",
    "LOAD DATA LOCAL INPATH 'journey/campaign_table.csv' OVERWRITE INTO TABLE campaign;\n",
    "\n",
    "/* --------------------\n",
    "load coupon.csv\n",
    "-------------------- */\n",
    "\n",
    "CREATE TABLE coupon\n",
    "(COUPON_UPC BIGINT,\n",
    "PRODUCT_ID INT,\n",
    "CAMPAIGN INT)\n",
    "ROW FORMAT DELIMITED\n",
    "FIELDS TERMINATED BY ','\n",
    "LINES TERMINATED BY '\\n'\n",
    "tblproperties (\"skip.header.line.count\"=\"1\");\n",
    "\n",
    "LOAD DATA LOCAL INPATH 'journey/coupon.csv' OVERWRITE INTO TABLE coupon;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now try to create a product table by converting MySQL code to Hive SQL. Use the external table command."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "$ hive -hiveconf DATA_DIR=/home/journey/ -f create_external_tables.hql"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "-- File: create_external_tables.hql\n",
    "\n",
    "USE journey;\n",
    "\n",
    "/* --------------------\n",
    "load hh_demographic.csv\n",
    "-------------------- */\n",
    "\n",
    "CREATE EXTERNAL TABLE IF NOT EXISTS hh_demographic\n",
    "(AGE_DESC VARCHAR(45),\n",
    "MARITAL_STATUS_CODE VARCHAR(10),\n",
    "INCOME_DESC VARCHAR(15),\n",
    "HOMEOWNER_DESC VARCHAR(45),\n",
    "HH_COMP_DESC VARCHAR(45),\n",
    "HOUSEHOLD_SIZE_DESC VARCHAR(20),\n",
    "KID_CATEGORY_DESC VARCHAR(5),\n",
    "HOUSEHOLD_KEY BIGINT)\n",
    "COMMENT 'Household Demographics in Journey'\n",
    "ROW FORMAT DELIMITED\n",
    "FIELDS TERMINATED BY ','\n",
    "LINES TERMINATED BY '\\n'\n",
    "tblproperties (\"skip.header.line.count\"=\"1\");\n",
    "\n",
    "LOAD DATA LOCAL INPATH 'journey/hh_demographic.csv' OVERWRITE INTO TABLE hh_demographic;\n",
    "\n",
    "/* --------------------\n",
    "load transaction_data.csv\n",
    "-------------------- */\n",
    "\n",
    "CREATE EXTERNAL TABLE IF NOT EXISTS transaction\n",
    "(HOUSEHOLD_KEY INT,\n",
    "BASKET_ID BIGINT,\n",
    "DAY INT,\n",
    "PRODUCT_ID BIGINT,\n",
    "QUANTITY INT,\n",
    "SALES_VALUE DECIMAL(10,2),\n",
    "STORE_ID INT,\n",
    "RETAIL_DISC DECIMAL(5,2),\n",
    "TRANS_TIME INT,\n",
    "WEEK_NO INT,\n",
    "COUPON_DISC DECIMAL(6,2),\n",
    "COUPON_MATCH_DISC DECIMAL(6,2))\n",
    "COMMENT 'transactions in Journey'\n",
    "ROW FORMAT DELIMITED\n",
    "FIELDS TERMINATED BY ','\n",
    "LINES TERMINATED BY '\\n'\n",
    "tblproperties (\"skip.header.line.count\"=\"1\");\n",
    "\n",
    "LOAD DATA LOCAL INPATH 'journey/transaction_data.csv' OVERWRITE INTO TABLE transaction;\n",
    "\n",
    "/* --------------------\n",
    "load campaign_desc.csv\n",
    "-------------------- */\n",
    "\n",
    "CREATE EXTERNAL TABLE IF NOT EXISTS campaign_desc\n",
    "(DESCRIPTION VARCHAR(15),\n",
    "CAMPAIGN INT,\n",
    "START_DAY INT,\n",
    "END_DAY INT)\n",
    "ROW FORMAT DELIMITED\n",
    "FIELDS TERMINATED BY ','\n",
    "LINES TERMINATED BY '\\n'\n",
    "tblproperties (\"skip.header.line.count\"=\"1\");\n",
    "\n",
    "LOAD DATA LOCAL INPATH 'journey/campaign_desc.csv' OVERWRITE INTO TABLE campaign_desc;\n",
    "\n",
    "/* --------------------\n",
    "load causal_data.csv\n",
    "-------------------- */\n",
    "\n",
    "CREATE EXTERNAL TABLE IF NOT EXISTS causal\n",
    "(PRODUCT_ID BIGINT,\n",
    "STORE_ID INT,\n",
    "WEEK_NO INT,\n",
    "DISPLAY VARCHAR(5),\n",
    "MAILER VARCHAR(5))\n",
    "ROW FORMAT DELIMITED\n",
    "FIELDS TERMINATED BY ','\n",
    "LINES TERMINATED BY '\\n'\n",
    "tblproperties (\"skip.header.line.count\"=\"1\");\n",
    "\n",
    "LOAD DATA LOCAL INPATH 'journey/causal_data.csv' OVERWRITE INTO TABLE causal;\n",
    "\n",
    "/* --------------------\n",
    "load coupon_redempt.csv\n",
    "-------------------- */\n",
    "\n",
    "CREATE EXTERNAL TABLE IF NOT EXISTS coupon_redempt\n",
    "(HOUSEHOLD_KEY BIGINT,\n",
    "DAY INT,\n",
    "COUPON_UPC BIGINT,\n",
    "CAMPAIGN INT)\n",
    "ROW FORMAT DELIMITED\n",
    "FIELDS TERMINATED BY ','\n",
    "LINES TERMINATED BY '\\n'\n",
    "tblproperties (\"skip.header.line.count\"=\"1\");\n",
    "\n",
    "LOAD DATA LOCAL INPATH 'journey/coupon_redempt.csv' OVERWRITE INTO TABLE coupon_redempt;\n",
    "\n",
    "/* --------------------\n",
    "load product.csv\n",
    "-------------------- */\n",
    "\n",
    "CREATE EXTERNAL TABLE IF NOT EXISTS product\n",
    "(PRODUCT_ID INT,\n",
    "MANUFACTURER INT,\n",
    "DEPARTMENT STRING,\n",
    "BRAND STRING,\n",
    "COMMODITY_DESC STRING,\n",
    "SUB_COMMODITY_DESC STRING,\n",
    "CURR_SIZE_OF_PRODUCT STRING)\n",
    "COMMENT 'journey product list cleaned'\n",
    "ROW FORMAT DELIMITED\n",
    "FIELDS TERMINATED BY ','\n",
    "LINES TERMINATED BY '\\n'\n",
    "tblproperties (\"skip.header.line.count\"=\"1\");\n",
    "\n",
    "LOAD DATA LOCAL INPATH 'journey/product.csv' OVERWRITE INTO TABLE product;\n",
    "\n",
    "/* --------------------\n",
    "load campaign_table.csv\n",
    "-------------------- */\n",
    "\n",
    "CREATE EXTERNAL TABLE IF NOT EXISTS campaign\n",
    "(DESCRIPTION VARCHAR(15),\n",
    "HOUSEHOLD_KEY BIGINT,\n",
    "CAMPAIGN INT)\n",
    "ROW FORMAT DELIMITED\n",
    "FIELDS TERMINATED BY ','\n",
    "LINES TERMINATED BY '\\n'\n",
    "tblproperties (\"skip.header.line.count\"=\"1\");\n",
    "\n",
    "LOAD DATA LOCAL INPATH 'journey/campaign_table.csv' OVERWRITE INTO TABLE campaign;\n",
    "\n",
    "/* --------------------\n",
    "load coupon.csv\n",
    "-------------------- */\n",
    "\n",
    "CREATE EXTERNAL TABLE IF NOT EXISTS coupon\n",
    "(COUPON_UPC BIGINT,\n",
    "PRODUCT_ID INT,\n",
    "CAMPAIGN INT)\n",
    "ROW FORMAT DELIMITED\n",
    "FIELDS TERMINATED BY ','\n",
    "LINES TERMINATED BY '\\n'\n",
    "tblproperties (\"skip.header.line.count\"=\"1\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a new table by joining transactions and demographics and\n",
    "keeping only households with kids. See hive slides on page 17 for\n",
    "help.\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "$ hive -hiveconf DATA_DIR=/home/JourneyData/ -f createTableFromJoin.hql"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "-- File: createTableFromJoin.hql\n",
    "\n",
    "use journey;\n",
    "CREATE TABLE TRANSACTION_DEMOGRAPHIC AS \n",
    "select b.household_key, b.basket_id, b.day, b.product_id, b.quantity, \n",
    "b.sales_value, b.store_id, b.retail_disc, b.trans_time, b.week_no, \n",
    "b.coupon_disc, b.coupon_match_disc, a.age_desc, a.marital_status_code, \n",
    "a.income_desc, a.homeowner_desc, a.hh_comp_desc, a.household_size_desc, \n",
    "a.kid_category_desc\n",
    "from TRANSACTION_DATA b JOIN HH_DEMOGRAPHIC a \n",
    "ON (a.HOUSEHOLD_KEY=b.HOUSEHOLD_KEY) \n",
    "and a.kid_category_desc != 'None/';"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the top 5 households with children in terms of purchases in dollars. Based on this data, do households with children spend more on average than households without children? Do a print screen to show your results.Create a new table by joining transactions and demographics and keeping only households with kids."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Top 5 households with kids"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "$ hive -e \"select sum(SALES_VALUE) as sum_sales_value from journey.TRANSACTION_DATA a join journey.HH_DEMOGRAPHIC b on (a.household_key=b.household_key) and b.KID_CATEGORY_DESC!='None/' group by b.household_key order by sum_sales_value desc limit 5;\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='image1.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Top 5 households without kids"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "$ hive -e \"select sum(SALES_VALUE) as sum_sales_value from journey.TRANSACTION_DATA a join journey.HH_DEMOGRAPHIC b on (a.household_key=b.household_key) and b.KID_CATEGORY_DESC='None/' group by b.household_key order by sum_sales_value desc limit 5;\""
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='image2.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (5) Partitioning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a partitioned Transaction_table partitioning by store_id."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "$ hive -hiveconf DATA_DIR=/home/JourneyData/ -f partitionedTable.hql"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "-- File: partitionedTable.hql\n",
    "\n",
    "use journey; \n",
    "\n",
    "set hive.exec.dynamic.partition=true;\n",
    "set hive.exec.dynamic.partition.mode=nonstrict;\n",
    "set hive.exec.max.dynamic.partitions.pernode=2000;\n",
    "\n",
    "CREATE TABLE Transaction_table \n",
    "(HOUSEHOLD_KEY INT, BASKET_ID BIGINT, DAY INT, PRODUCT_ID BIGINT, QUANTITY INT, SALES_VALUE DECIMAL(10,2), RETAIL_DISC DECIMAL(5,2), TRANS_TIME INT, WEEK_NO INT, COUPON_DISC DECIMAL(6,2), COUPON_MATCH_DISC DECIMAL(6,2))\n",
    "PARTITIONED BY (STORE_ID INT)\n",
    "ROW FORMAT DELIMITED\n",
    "FIELDS TERMINATED BY ','\n",
    "LINES TERMINATED BY '\\n'\n",
    "tblproperties (\"skip.header.line.count\"=\"1\");\n",
    "\n",
    "insert overwrite table transaction_table PARTITION (store_id) \n",
    "select household_key, basket_id, day, product_id, quantity, sales_value, \n",
    "retail_disc, trans_time, week_no, coupon_disc, coupon_match_disc, store_id     \n",
    "from transaction_data;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open a second shell window and check in the hive directories for the partitioned table. Take a screen shot and turn that in."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "$ hive -e 'describe journey.transaction_table;'"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='image3.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "................NEED TO DO................\n",
    "\n",
    "Find out why there are no seperate directories for the partitioned table."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Querying partitioned table:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "$ hive -e 'select count(distinct household_key) as number_households from journey.transaction_table where store_id=310;'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='image4.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Querying full table:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "$ hive -e 'select count(distinct household_key) as number_households from journey.transaction_data where store_id=310;'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='image5.png'>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (5) Create an External Table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the product data into HDFS using appropriate commands (already done in step 4). Show how to create an external table on top of this HDFS file."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "$ hive -e 'export table journey.product to \"journey/product\";'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "................NEED TO DO................\n",
    "\n",
    "Explain the value of an external table."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (6) Run a Batch Job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (7) Clean up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Delete data (scripts) from S3 bucket."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "$ exit # close ssh connection\n",
    "$ aws s3 rm ss3://kjgardner74-hive/scripts --recursive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Terminate EMR Cluster."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "$ aws emr modify-cluster-attributes --cluster-id j-1CZ51HG5J04RV --no-termination-protected\n",
    "$ aws emr terminate-clusters --cluster-ids j-1CZ51HG5J04RV"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
